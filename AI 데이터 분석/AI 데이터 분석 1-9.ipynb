{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 머신러닝의 다양한 알고리즘의 한 종류인 인공 신경망 알고리즘을 이용한 기계학습  \n",
    "(인공 신경망 알고리즘 : 인간의 뇌가 학습하는 방법을 수학적으로 모델링한 머신러닝 알고리즘)\n",
    "- 높은 정확도를 얻을 수 있음\n",
    "- 방대한 양의 학습 데이터와 높은 성능의 하드웨어가 필요함\n",
    "- 머신러닝에 비해 학습 시간이 오래걸림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 기초를 이루는 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가장 훌륭한 예측선 긋기**\n",
    "- y = ax+b\n",
    "- a = 기울기(x의 증가량/y의 증가량)\n",
    "- b = y 절편\n",
    "\n",
    "\n",
    "**잘못 그은 선 바로 잡기**\n",
    "- 임의의 직선을 그어 그에 대한 평균 제곱근 오차를 구하고 이 값을 가장 작게  \n",
    " 만들어주는 a와 b를 찾아가는 작업\n",
    "- 평균 제곱근 오차 = 루트(오차 제곱의 합/n)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**가장 훌륭한 예측 평면 찾기**\n",
    "- y = a1x1+a2x2+b\n",
    "- a1과 a2 : 기울기\n",
    "- b : y절편"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터에서 최적의 직선을 찾고 참(1)과 거짓(0)으로 분류하는 **s자 형태의 적절한 선**을 찾아가는 작업  \n",
    "(예) 합격과 불합격 판단하기)\n",
    "- 딥러닝의 기본적인 요소로 사용되는 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망(Aritificial Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인간의 뇌가 학습하는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 뉴런이 여러 수상돌기(input)를 통해 전기적 또는 화학적인 신호를 받아들이고 축색돌기(output)에서 신호를 전송\n",
    "2. 뉴런 사이는 스냅스로 연결, 신호가 전달되기 위해서는 일정 기준(임계값: 자극의 총합) 이상의 신호가 존재해야 함\n",
    "3. 뉴런 사이의 신호 전달을 통해 정보를 전달하고 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 인공신경망 구조(구성요소)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input(x)이 들어오면 가중치(w)가 곱해짐  \n",
    "- 그 값들의 합(Y)이 어느 임계값보다 크면 1을 다음 노드(뉴런)의 입력으로 보냄  \n",
    " (0은 출력이 없는 상태와 같음)  \n",
    "- 0과 1을 판단하는 함수를 활성화 함수(activation function)이라고 함  \n",
    "(Y > 0 : output 1)  \n",
    "(Y <= 0 : output 2)\n",
    "\n",
    "**퍼셉트론**  \n",
    "w1 x 1 + w2 x 2 + w3 x 3 + b = u  \n",
    "f(u) =Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 퍼셉트론(perceptron)\n",
    "- 신경망을 이루는 가장 중요한 기본 단위\n",
    "- 입력 값과 활성화 함수를 사용해 출력 값을 다음으로 넘기는 가장 작은 신경망\n",
    "  단위"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 활성화 함수(activation function)\n",
    "- 입력 신호를 받아 특정 값의 임계점을 넘어서는 경우에, 출력을 생성해주는 함수\n",
    "- 임계값이 높으면 높을 수록 분류 기준이 엄격함을 의미\n",
    "- sigmoid, ReLU, Leaky ReLU, hyperbolic tangent(tanh)등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 가중치(weight)\n",
    "- 입력신호가 결과 출력에 주는 영향도를 조절하는 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 편향(bias)\n",
    "- 뉴런이 얼마나 쉽게 활성화(1로 출력: activation)되느냐를 조정하는 매개변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퍼셉트론을 통한 문제 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력층과 출력층만으로 구성된 퍼셉트론\n",
    "입력--x1 --w1--u/f--출력\n",
    "입력--x2 --w2--u/f--출력\n",
    "입력--x3 --w3--u/f--출력\n",
    "\n",
    "# 문제 : 새로운 스마트폰을 구매해야 할까?\n",
    "- 구매하겠다 : 출력 y에 1\n",
    "- 구매하지 않겠다 : 출력 y에 0\n",
    "- 관련된 요인\n",
    " -- 이번 달의 수입이 충분한가?(x1)\n",
    " -- 최신 기능을 가지고 있는가?(x2)\n",
    " -- 기존의 스마트폰에 문제가 있는가?(x3)\n",
    "    \n",
    "# 절반 이상(2개) 만족하면 스마트폰을 구매해도 될까?\n",
    "- 엄청난 부자라면 수입과 관련된 조건(x1)은 의미없음\n",
    "- 수입이 적더라도 현재 스마트폰이 고장나서 세번재 조건(x3)이 정말로 중요해지는\n",
    " 경우도 존재\n",
    "- \"몇 개의 조건을 만족한다\"라는 것만으로는 최종적인 판단 불가\n",
    "\n",
    "# 각 입력에 대해 가중치(w) 매개변수 도입\n",
    "- x1,x2,x3에 대한 가중치 w1,w2,w3라고 할 때 설정\n",
    " -- 부자: w1=1,w2=8, w3=3\n",
    " -- 스마트폰이 고장난 사람: w1=3,w2=2,w3=8\n",
    " -- 정기적으로 최신 스마트폰을 구입하는 사람: w1=3,w2=6,w3=5\n",
    "    \n",
    "# 구입할지 검토하는 바이어스 값을(선택의 기준이 되는 값) b라고 할 때 코드\n",
    "if (x1*w1) + (x2*w2) + (x3*w3) + b > 0:\n",
    "    구매\n",
    "else:\n",
    "    구매하지 않음\n",
    "    \n",
    "- 가중치와 바이어스를 변경하면 상황에 맞게 의사결정 가능\n",
    "- 여러가지 정보를 고려해서 가중치를 변경하다 보면 어떤 정도의 가중치가 좋은\n",
    "  결정을 내리는지 가능\n",
    "- 퍼셉트론을 여러 개 조합하면 더 복잡한 것들도 판단 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인공신경망(Artificial Neural Networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다층 인공 신경망의 구조"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 노드가 서로 연결된 구조의 신경망\n",
    "- 입력층에 학습시키고 싶은 데이터를 입력\n",
    "- 데이터들이 입력층, 중간층(은익층), 출력층을 지나며 처리되고 최종결과 출력\n",
    "\n",
    "입력 -- 입력층--중간층(은닉층)--출력층--출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝의 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝의 학습이란 다층 신경망 구조에서 출력층에서의 오차가 최소가 되도록  \n",
    "  각 노드(뉴런)을 연결하는 접속 가중치와 편향 값을 학습과정\n",
    "- 노드가 서로 연결되어 있는 신경망 구조에서 1개 이상의 은익층을 두어  \n",
    "  (은익층을 깊게 할수록) 학습하면 정확도가 높은 결과를 얻을 수 있다하여 사용된 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝이 문제를 해결하는 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사진을 보고 개와 고양이인지 구분하는 예"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동물이 수염이 있는지, 없는지, 귀가 있는지 없는지, 솟아 있는지 등의 특징을\n",
    "  확인하여 입력값으로 들어감\n",
    "- 시스템으로 무엇이 특정 동물을 더 잘 묘사하는지 구분\n",
    "- 딥러닝은 중요한 특징을 자동적으로 골라냄\n",
    "- 머신러닝은 수동적으로 중요한 특징을 골라냄\n",
    "\n",
    "- 딥러닝은 어떤 정보가 개와 고양이를 가장 잘 구분할지를 찾는 것\n",
    "\n",
    "- 머신러닝보다 사람이 개입하는 정도가 작음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow와 Keras 라이브러리를 이용한 딥러닝 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TensorFlow(텐서플로우)는 대표적인 딥러닝 라이브러리\n",
    "    - 딥러닝을 구동시키는 라이브러리는 카페(caffe), 파이토치(pytorch)등 다양함\n",
    "- TensorFlow 홈페이지  \n",
    " https://www.tensorflow.org/api_docs/python/ (아나콘다 배포판에 포함되지 않아 별도 설치 필요)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keras(케라스)는 딥러닝 모델을 쉽게 구현하도록 해주는 딥러닝 상위 레벨 라이브러리\n",
    "- 케라스가 구동되려면 텐서플로가 설치되어 있어야 함\n",
    "- Keras 홈페이지  \n",
    " https://keras.io/ (아나콘다 배포판에 없어 별도 설치 필요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 작업 환경 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아나콘다에서 설치된 라이브러리 확인\n",
    "- 아나콘다 prompt ->pip list\n",
    "# 텐서플로 설치\n",
    "- pip install tensorflow\n",
    "# 케라스 설치\n",
    "- pip install keras\n",
    "# 확인\n",
    "- pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 폐암 수술 환자의 생존율 예측하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폐암 환자의 의료 기록 데이터\n",
    "- 폴란드 브로츠와프 의과대학에서 2013년 공개한 수술 환자의 수술 전 진단 데이터와\n",
    "  수술 후 생존 결과를 기록한 의료 기록 데이터\n",
    "(https://archive.ics.uci.edu/ml/datasets/Thoracic+Surgery+Data)\n",
    " 스마트캠퍼스에서 다운 : thoracic_surgery.csv - C:\\myCode\\data\\에 저장\n",
    "            \n",
    "# 폐암 수술 환자의 기록: 470개 라인, 18개 항목으로 구성\n",
    "속성 : 종양의 유형, 폐활량, 호흡 곤란 여부, 고통 정도, 기침, 흡연, 천식 여부 등의\n",
    "      수술 전 환자 상태\n",
    "- 1은 해당 사항이 있음, 0은 해당 사항이 없음을 의미\n",
    "\n",
    "클래스 : 수술 후 생존 결과 1은 생존, 0은 사망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 분리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋을 학습 데이터와 테스트 데이터로 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[293.  ,   1.  ,   3.8 , ...,   0.  ,  62.  ,   0.  ],\n",
       "       [  1.  ,   2.  ,   2.88, ...,   0.  ,  60.  ,   0.  ],\n",
       "       [  8.  ,   2.  ,   3.19, ...,   0.  ,  66.  ,   1.  ],\n",
       "       ...,\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,  62.  ,   0.  ],\n",
       "       [ 25.  ,   8.  ,   4.32, ...,   0.  ,  58.  ,   1.  ],\n",
       "       [447.  ,   8.  ,   5.2 , ...,   0.  ,  49.  ,   0.  ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\user\\Documents\\주피터노트북\\data\\thoraric_surgery.csv')\n",
    "Data_set = df.values\n",
    "Data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[270.  ,   3.  ,   4.28, ...,   1.  ,   0.  ,  71.  ],\n",
       "       [381.  ,   3.  ,   3.76, ...,   1.  ,   0.  ,  52.  ],\n",
       "       [331.  ,   2.  ,   2.94, ...,   0.  ,   0.  ,  61.  ],\n",
       "       ...,\n",
       "       [ 16.  ,   3.  ,   4.68, ...,   1.  ,   0.  ,  62.  ],\n",
       "       [370.  ,   3.  ,   3.8 , ...,   1.  ,   0.  ,  59.  ],\n",
       "       [441.  ,   3.  ,   3.  , ...,   1.  ,   0.  ,  65.  ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터셋에서 학습 데이터와 테스트데이터를 분리\n",
    "train,test = train_test_split(Data_set,test_size=0.2)\n",
    "\n",
    "# 속성과 클래스 분리하기\n",
    "X_train = train[:,0:17]\n",
    "Y_train = train[:,17]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 47.  ,   3.  ,   4.16, ...,   1.  ,   0.  ,  67.  ],\n",
       "       [465.  ,   3.  ,   3.08, ...,   1.  ,   0.  ,  79.  ],\n",
       "       [ 94.  ,   3.  ,   6.08, ...,   1.  ,   0.  ,  50.  ],\n",
       "       ...,\n",
       "       [335.  ,   2.  ,   4.  , ...,   1.  ,   0.  ,  67.  ],\n",
       "       [ 54.  ,   4.  ,   3.76, ...,   1.  ,   0.  ,  75.  ],\n",
       "       [406.  ,   6.  ,   5.36, ...,   0.  ,   0.  ,  62.  ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test[:,0:17]\n",
    "Y_test = test[:,17]\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력층, 은익층, 출력층 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력층, 은익층, 출력층의 딥러닝 구조를 짜고 층을 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sequential()로 딥러닝 구조의 모델 객체를 생성\n",
    "- Sequential 모델 객체의 add() 메서드로 층을 추가\n",
    "- 각각의 층은 Dense() 객체를 통해 구체적인 구조가 결정 됨\n",
    "    - Keras는 입력층을 따로 만들지 않고 첫 번째 Dense가 은익층 + 입력층의 역할을 겸함\n",
    "    - 인수 : 각 층의 노드 수, input_dim = 입력 값의 수, activation = 사용할 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential    ### keras.models 라고하면 안 나오고, tensorflow.keras.models라고 해야 함\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# 딥러닝 구조 모델인 Sequential 객체, model 생성\n",
    "model=Sequential()\n",
    "\n",
    "# 2개의 층을 추가\n",
    "model.add(Dense(30, input_dim =17, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.python.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 컴파일하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile() 메소드 : 모델을 더 효과적으로 구현할 학습환경을 설정하여 완성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loss =  한 번 신경망이 실행될 때마다 오차 값을 추적하는 함수,\n",
    "    - mean_squared_error : 평균 제곱 오차\n",
    "- optimizer = 오차를 어떻게 줄여 나갈지 정하는 함수\n",
    "- metrics = 학습과 테스트 단계에서 모델을 평가하기 위한 성능 기준을 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 실행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit() 메소드 : 학습 데이터를 가지고 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- epochs(에포크) = 각 샘플(데이터에서 한 행 : 한 환자의 기록)을 반복하여 실행하는 횟수\n",
    "    - epochs = 30 : 처음부터 끝까지 30번 재사용 될 때까지 실행을 반복\n",
    "- batch_size = 샘플을 한 번에 처리하는 개수\n",
    "    - batch_size = 10 : 전체 입력 샘플을 10개씩 끊어서 집어 넣음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 376 samples\n",
      "Epoch 1/30\n",
      "376/376 [==============================] - 0s 507us/sample - loss: 0.1441 - accuracy: 0.8537\n",
      "Epoch 2/30\n",
      "376/376 [==============================] - 0s 467us/sample - loss: 0.1449 - accuracy: 0.8511\n",
      "Epoch 3/30\n",
      "376/376 [==============================] - 0s 440us/sample - loss: 0.1440 - accuracy: 0.8511\n",
      "Epoch 4/30\n",
      "376/376 [==============================] - 0s 448us/sample - loss: 0.1436 - accuracy: 0.8537\n",
      "Epoch 5/30\n",
      "376/376 [==============================] - 0s 480us/sample - loss: 0.1453 - accuracy: 0.8511\n",
      "Epoch 6/30\n",
      "376/376 [==============================] - 0s 536us/sample - loss: 0.1435 - accuracy: 0.8537\n",
      "Epoch 7/30\n",
      "376/376 [==============================] - 0s 708us/sample - loss: 0.1432 - accuracy: 0.8537\n",
      "Epoch 8/30\n",
      "376/376 [==============================] - 0s 557us/sample - loss: 0.1428 - accuracy: 0.8537\n",
      "Epoch 9/30\n",
      "376/376 [==============================] - 0s 724us/sample - loss: 0.1419 - accuracy: 0.8484\n",
      "Epoch 10/30\n",
      "376/376 [==============================] - 0s 509us/sample - loss: 0.1434 - accuracy: 0.8511\n",
      "Epoch 11/30\n",
      "376/376 [==============================] - 0s 605us/sample - loss: 0.1430 - accuracy: 0.8537\n",
      "Epoch 12/30\n",
      "376/376 [==============================] - 0s 767us/sample - loss: 0.1425 - accuracy: 0.8537\n",
      "Epoch 13/30\n",
      "376/376 [==============================] - 0s 554us/sample - loss: 0.1429 - accuracy: 0.8511\n",
      "Epoch 14/30\n",
      "376/376 [==============================] - 0s 488us/sample - loss: 0.1418 - accuracy: 0.8537\n",
      "Epoch 15/30\n",
      "376/376 [==============================] - 0s 477us/sample - loss: 0.1423 - accuracy: 0.8511\n",
      "Epoch 16/30\n",
      "376/376 [==============================] - 0s 469us/sample - loss: 0.1417 - accuracy: 0.8537\n",
      "Epoch 17/30\n",
      "376/376 [==============================] - 0s 472us/sample - loss: 0.1420 - accuracy: 0.8537\n",
      "Epoch 18/30\n",
      "376/376 [==============================] - 0s 456us/sample - loss: 0.1410 - accuracy: 0.8537\n",
      "Epoch 19/30\n",
      "376/376 [==============================] - 0s 488us/sample - loss: 0.1419 - accuracy: 0.8537\n",
      "Epoch 20/30\n",
      "376/376 [==============================] - 0s 472us/sample - loss: 0.1402 - accuracy: 0.8511\n",
      "Epoch 21/30\n",
      "376/376 [==============================] - 0s 809us/sample - loss: 0.1415 - accuracy: 0.8511\n",
      "Epoch 22/30\n",
      "376/376 [==============================] - 0s 963us/sample - loss: 0.1414 - accuracy: 0.8537\n",
      "Epoch 23/30\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.1401 - accuracy: 0.8511\n",
      "Epoch 24/30\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.1415 - accuracy: 0.8537\n",
      "Epoch 25/30\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.1419 - accuracy: 0.85640s - loss: 0.1515 - accu\n",
      "Epoch 26/30\n",
      "376/376 [==============================] - 0s 1ms/sample - loss: 0.1398 - accuracy: 0.8537\n",
      "Epoch 27/30\n",
      "376/376 [==============================] - 0s 679us/sample - loss: 0.1414 - accuracy: 0.8537 - loss: 0.0631 - accuracy\n",
      "Epoch 28/30\n",
      "376/376 [==============================] - 0s 549us/sample - loss: 0.1397 - accuracy: 0.8537\n",
      "Epoch 29/30\n",
      "376/376 [==============================] - 0s 491us/sample - loss: 0.1447 - accuracy: 0.8484\n",
      "Epoch 30/30\n",
      "376/376 [==============================] - 0s 472us/sample - loss: 0.1448 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x237ee85af88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, epochs=30, batch_size =10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델을 평가하고 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate() 메소드 : 생성한 딥러닝 모델이 어느 정도 정확하게 예측하는지 점검\n",
    "- 테스트 환자들의 데이터 중 일부를 랜덤하게 추출해, 테스트한 정확도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 0s 180us/sample - loss: 0.1479 - accuracy: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.14790351213292874, 0.85106385]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict_classes() 메소드 : 생성한 딥러닝 모델을 이용하여 생존 여부 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict_classes(X_test)\n",
    "prediction.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 평가하고 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    prediction  ground_truth\n",
       "0            0             0\n",
       "1            0             0\n",
       "2            0             0\n",
       "3            0             0\n",
       "4            0             0\n",
       "..         ...           ...\n",
       "89           0             0\n",
       "90           0             1\n",
       "91           0             1\n",
       "92           0             0\n",
       "93           0             0\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "comparison = pd.DataFrame({'prediction':prediction.ravel(), 'ground_truth':Y_test.astype(int)})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow와 Keras를 이용한 딥러닝 순서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sequential 모형 클래스 객체 생성\n",
    "2. add 메서드로 레이어 추가\n",
    " - 입력단부터 각 층은 Dense 함수로 추가\n",
    "    - 레이어는 출력 노드(뉴런) 개수를 첫 번째 인수로 받음\n",
    "    - 최초의 레이어는 input_dim 인수로 입력 크기를 설정\n",
    "    - activation 인수로 활성화함수 설정\n",
    "3. compile 메서드로 모형 완성\n",
    " - loss 인수로 비용함수 설정\n",
    " - optimizer 인수로 최적화 알고리즘 설정\n",
    " - metrics 인수로 학습 단계에서 기록할 성능 기준 설정\n",
    "4. fit 메서드로 학습\n",
    " - epoch로 에포크(epoch-학습 샘플 재사용 횟수) 횟수 설정\n",
    " - batch_size로 배치크기(batch size) 설정\n",
    "5. evaluate 메서도르 모델 평가하기\n",
    "6. predict 메서도르 예측하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
